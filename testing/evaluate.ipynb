{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5002\n",
      " * Running on http://192.168.29.104:5002\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priti V\\collegeproject\\ML\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load trained response analysis model (Train it if not done)\n",
    "response_analyzer = joblib.load(\"C:/Users/Priti V/collegeproject/ML/models/student_response_analyzer.pkl\")\n",
    "\n",
    "# Ensure directory exists for reports\n",
    "os.makedirs(\"static/reports\", exist_ok=True)\n",
    "\n",
    "@app.route(\"/analyze_response\", methods=[\"POST\"])\n",
    "def analyze_response():\n",
    "    data = request.json  # Expecting a JSON payload with 'student_id' and 'responses'\n",
    "    student_id = data.get(\"student_id\")\n",
    "    responses = pd.DataFrame(data.get(\"responses\"))\n",
    "    \n",
    "    # Check if correct answers\n",
    "    responses['Correct'] = responses['Selected Answer'] == responses['Correct Answer']\n",
    "    \n",
    "    # Calculate skill performance\n",
    "    skill_performance = responses.groupby('Skill Type')['Correct'].mean() * 100\n",
    "    \n",
    "    # Generate bar chart\n",
    "    img_path = f\"static/reports/student_{student_id}.png\"\n",
    "    skill_performance.plot(kind='bar', color=['blue', 'green', 'red'])\n",
    "    plt.xlabel(\"Skills\")\n",
    "    plt.ylabel(\"Performance (%)\")\n",
    "    plt.title(f\"Student {student_id} Performance Report\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.savefig(img_path)  # Save image\n",
    "    plt.close()\n",
    "    \n",
    "    return jsonify({\"message\": \"Report generated!\", \"image_url\": f\"http://127.0.0.1:5002/{img_path}\"})\n",
    "\n",
    "# Serve static images\n",
    "@app.route(\"/static/reports/<filename>\")\n",
    "def get_report_image(filename):\n",
    "    return send_file(f\"static/reports/{filename}\", mimetype=\"image/png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5002, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load student responses dataset\n",
    "df = pd.read_csv(\"C:/Users/Priti V/collegeproject/ML/data/raw/student_responses.csv\")\n",
    "\n",
    "def analyze_student_performance(student_id):\n",
    "    \"\"\"\n",
    "    Analyze student responses and generate a performance report.\n",
    "    \"\"\"\n",
    "    # Filter data for the given student\n",
    "    student_data = df[df[\"Student ID\"] == student_id]\n",
    "\n",
    "    if student_data.empty:\n",
    "        print(f\"No data found for Student ID: {student_id}\")\n",
    "        return\n",
    "\n",
    "    # Check correctness of answers\n",
    "    student_data[\"Correct\"] = student_data[\"Selected Answer\"] == student_data[\"Correct Answer\"]\n",
    "\n",
    "    # Calculate performance by skill type\n",
    "    skill_performance = student_data.groupby(\"Skill Type\")[\"Correct\"].mean() * 100\n",
    "\n",
    "    # Plot bar chart for visualization\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x=skill_performance.index, y=skill_performance.values, palette=\"viridis\")\n",
    "    plt.xlabel(\"Skill Type\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(f\"Student Performance Report (ID: {student_id})\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Save the generated report\n",
    "    os.makedirs(\"static/reports\", exist_ok=True)\n",
    "    report_path = f\"static/reports/student_{student_id}_report.png\"\n",
    "    plt.savefig(report_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Report generated and saved at: {report_path}\")\n",
    "    return report_path\n",
    "\n",
    "# Example usage:\n",
    "# analyze_student_performance(student_id=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after encoding:\n",
      " Question_Type_Preference         int64\n",
      "Most_Challenging_Topic           int64\n",
      "Problem_Solving_Speed          float64\n",
      "Error_Analysis                   int64\n",
      "Confidence_in_Math             float64\n",
      "Confidence_in_Concepts         float64\n",
      "Memorization_vs_Application    float64\n",
      "Time_Management                float64\n",
      "Recommended_Topic                int64\n",
      "dtype: object\n",
      "\n",
      "All data encoded correctly!\n",
      "Recommended Topics:\n",
      "1. 4\n",
      "2. 4\n",
      "3. 8\n",
      "4. 5\n",
      "5. 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load survey data and recommendations dataset\n",
    "math_df = pd.read_csv('C:/Users/Priti V/collegeproject/ML/data/survey_question/math_survey.csv')\n",
    "chemistry_df = pd.read_csv('C:/Users/Priti V/collegeproject/ML/data/survey_question/chemistry_survey.csv')\n",
    "physics_df = pd.read_csv('C:/Users/Priti V/collegeproject/ML/data/survey_question/physics_survey.csv')\n",
    "topics_df = pd.read_csv('C:/Users/Priti V/collegeproject/ML/data/recommendation_data/topic_recommendation.csv')\n",
    "\n",
    "# Initialize encoders\n",
    "encoder_dict = {}\n",
    "topic_encoder = LabelEncoder()\n",
    "\n",
    "# Function to encode categorical columns\n",
    "def encode_df(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            # Collect unique values from all datasets for this column\n",
    "            unique_values = np.array([])\n",
    "            for dataset in [math_df, chemistry_df, physics_df, topics_df]:\n",
    "                if column in dataset.columns:\n",
    "                    unique_values = np.unique(np.concatenate((unique_values, dataset[column].astype(str).unique())))\n",
    "            # Create encoder if it doesn't exist\n",
    "            if column not in encoder_dict:\n",
    "                encoder_dict[column] = LabelEncoder()\n",
    "                encoder_dict[column].fit(unique_values)\n",
    "            # Encode the column (handle unknown values)\n",
    "            df[column] = df[column].apply(\n",
    "                lambda x: encoder_dict[column].transform([str(x)])[0] \n",
    "                if str(x) in encoder_dict[column].classes_ \n",
    "                else -1  # Assign -1 for unknown values\n",
    "            )\n",
    "    return df\n",
    "\n",
    "# Encode all datasets (including topics_df)\n",
    "math_df = encode_df(math_df)\n",
    "chemistry_df = encode_df(chemistry_df)\n",
    "physics_df = encode_df(physics_df)\n",
    "topics_df = encode_df(topics_df)\n",
    "\n",
    "# Encode the target variable ('Recommended_Topic') separately\n",
    "topics_df['Recommended_Topic'] = topic_encoder.fit_transform(topics_df['Recommended_Topic'])\n",
    "\n",
    "# Combine all datasets\n",
    "combined_df = pd.concat([math_df, chemistry_df, physics_df, topics_df], axis=0)\n",
    "\n",
    "# Handle missing values (use mode for categorical data)\n",
    "# Handle missing values and cast to integer\n",
    "combined_df.fillna(combined_df.mode().iloc[0], inplace=True)\n",
    "combined_df['Recommended_Topic'] = combined_df['Recommended_Topic'].astype(int)  # Add this line\n",
    "\n",
    "\n",
    "\n",
    "# Encode the target variable ('Recommended_Topic') as integer\n",
    "topics_df['Recommended_Topic'] = topic_encoder.fit_transform(topics_df['Recommended_Topic'].astype(str))\n",
    "\n",
    "\n",
    "# Verify that all columns are numeric\n",
    "print(\"Data types after encoding:\\n\", combined_df.dtypes)\n",
    "if not all(np.issubdtype(dtype, np.number) for dtype in combined_df.dtypes):\n",
    "    print(\"\\nError: Non-numeric columns found:\", combined_df.select_dtypes(exclude=[np.number]).columns)\n",
    "else:\n",
    "    print(\"\\nAll data encoded correctly!\")\n",
    "\n",
    "# Train KNN model\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "X = combined_df.drop(columns=['Recommended_Topic']).values  # Exclude the target column\n",
    "knn.fit(X)\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_topics(new_response):\n",
    "    if len(new_response) != X.shape[1]:\n",
    "        raise ValueError(f\"New response must have {X.shape[1]} features.\")\n",
    "    \n",
    "    encoded_response = []\n",
    "    for val, col in zip(new_response, combined_df.columns[:-1]):  # Exclude 'Recommended_Topic'\n",
    "        if col in encoder_dict:\n",
    "            # Handle unknown values gracefully\n",
    "            encoded_val = (\n",
    "                encoder_dict[col].transform([str(val)])[0] \n",
    "                if str(val) in encoder_dict[col].classes_ \n",
    "                else -1\n",
    "            )\n",
    "            encoded_response.append(encoded_val)\n",
    "        else:\n",
    "            encoded_response.append(val)\n",
    "    \n",
    "    distances, indices = knn.kneighbors([encoded_response])\n",
    "    recommended_encoded_topics = combined_df.iloc[indices[0]]['Recommended_Topic']\n",
    "    recommended_topics = topic_encoder.inverse_transform(recommended_encoded_topics)\n",
    "    \n",
    "    print(\"Recommended Topics:\")\n",
    "    for i, topic in enumerate(recommended_topics, 1):\n",
    "        print(f\"{i}. {topic}\")\n",
    "\n",
    "# Example usage\n",
    "new_response = [\"Like\", \"Medium\", \"Yes\", \"No\", \"Like\", \"High\", \"Yes\", \"Yes\"]\n",
    "recommend_topics(new_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n",
      " Question_Type_Preference       float64\n",
      "Most_Challenging_Topic         float64\n",
      "Problem_Solving_Speed          float64\n",
      "Error_Analysis                   int64\n",
      "Confidence_in_Math             float64\n",
      "Confidence_in_Concepts         float64\n",
      "Memorization_vs_Application    float64\n",
      "Time_Management                float64\n",
      "Recommended_Topic              float64\n",
      "dtype: object\n",
      "\n",
      "All data encoded correctly!\n",
      "KNN model trained successfully!\n",
      "Recommended Topics:\n",
      "1. Organic Chemistry\n",
      "2. Geometry\n",
      "3. Algebra\n",
      "4. Classical Mechanics\n",
      "5. Calculus\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load survey data and recommendations dataset\n",
    "math_df = pd.read_csv('C:/Users/Priti V/collegeproject/ML/data/survey_question/math_survey.csv')\n",
    "chemistry_df = pd.read_csv('C:/Users/Priti V/collegeproject/ML/data/survey_question/chemistry_survey.csv')\n",
    "physics_df = pd.read_csv('C:/Users/Priti V/collegeproject/ML/data/survey_question/physics_survey.csv')\n",
    "topics_df = pd.read_csv('C:/Users/Priti V/collegeproject/ML/data/recommendation_data/topic_recommendation.csv')\n",
    "\n",
    "# Initialize encoders\n",
    "encoder_dict = {}\n",
    "topic_encoder = LabelEncoder()\n",
    "\n",
    "# Function to encode categorical columns\n",
    "def encode_df(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            # Collect unique values from all datasets for this column\n",
    "            unique_values = np.array([])\n",
    "            for dataset in [math_df, chemistry_df, physics_df, topics_df]:\n",
    "                if column in dataset.columns:\n",
    "                    unique_values = np.unique(np.concatenate((unique_values, dataset[column].astype(str).unique())))\n",
    "            # Create encoder if it doesn't exist\n",
    "            if column not in encoder_dict:\n",
    "                encoder_dict[column] = LabelEncoder()\n",
    "                encoder_dict[column].fit(unique_values)\n",
    "            # Encode the column (handle unknown values)\n",
    "            df[column] = df[column].apply(\n",
    "                lambda x: encoder_dict[column].transform([str(x)])[0] \n",
    "                if str(x) in encoder_dict[column].classes_ \n",
    "                else -1  # Assign -1 for unknown values\n",
    "            )\n",
    "    return df\n",
    "\n",
    "# Encode all datasets (including topics_df)\n",
    "math_df = encode_df(math_df)\n",
    "chemistry_df = encode_df(chemistry_df)\n",
    "physics_df = encode_df(physics_df)\n",
    "\n",
    "# Encode the target variable ('Recommended_Topic') separately\n",
    "topics_df['Recommended_Topic'] = topic_encoder.fit_transform(topics_df['Recommended_Topic'])\n",
    "\n",
    "# Combine all datasets\n",
    "combined_df = pd.concat([math_df, chemistry_df, physics_df, topics_df], axis=0)\n",
    "\n",
    "# Ensure that all encoded columns are numeric\n",
    "for column in combined_df.columns:\n",
    "    combined_df[column] = pd.to_numeric(combined_df[column], errors='coerce').fillna(-1)\n",
    "\n",
    "# Check if all columns are numeric\n",
    "print(\"Data types after conversion:\\n\", combined_df.dtypes)\n",
    "if not all(np.issubdtype(dtype, np.number) for dtype in combined_df.dtypes):\n",
    "    print(\"\\nError: Non-numeric columns found:\", combined_df.select_dtypes(exclude=[np.number]).columns)\n",
    "else:\n",
    "    print(\"\\nAll data encoded correctly!\")\n",
    "\n",
    "# Train KNN model\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "X = combined_df.drop(columns=['Recommended_Topic']).values  # Exclude the target column\n",
    "\n",
    "try:\n",
    "    knn.fit(X)\n",
    "    print(\"KNN model trained successfully!\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error during KNN fitting: {e}\")\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_topics(new_response):\n",
    "    if len(new_response) != X.shape[1]:\n",
    "        raise ValueError(f\"New response must have {X.shape[1]} features.\")\n",
    "    \n",
    "    encoded_response = []\n",
    "    for val, col in zip(new_response, combined_df.columns[:-1]):  # Exclude 'Recommended_Topic'\n",
    "        if col in encoder_dict:\n",
    "            # Handle unknown values gracefully\n",
    "            encoded_val = (\n",
    "                encoder_dict[col].transform([str(val)])[0] \n",
    "                if str(val) in encoder_dict[col].classes_ \n",
    "                else -1\n",
    "            )\n",
    "            encoded_response.append(encoded_val)\n",
    "        else:\n",
    "            encoded_response.append(val)\n",
    "    \n",
    "    distances, indices = knn.kneighbors([encoded_response])\n",
    "    recommended_encoded_topics = combined_df.iloc[indices[0]]['Recommended_Topic']\n",
    "    recommended_topics = topic_encoder.inverse_transform(recommended_encoded_topics.astype(int))  # Convert to int before inverse_transform\n",
    "    \n",
    "    print(\"Recommended Topics:\")\n",
    "    for i, topic in enumerate(recommended_topics, 1):\n",
    "        print(f\"{i}. {topic}\")\n",
    "\n",
    "# Example usage\n",
    "new_response = [\"Like\", \"Medium\", \"Yes\", \"No\", \"Like\", \"High\", \"Yes\", \"Yes\"]\n",
    "recommend_topics(new_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
